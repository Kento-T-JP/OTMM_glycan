Google Colaboratoryの実行結果はCPUなどの環境がすべて同じとは限らないので、学習済みパラメータと尤度の推移のみ利用する。

Google Colaboratoryの実行時間は参考程度にすること！

また、データ数のmaxは5195である。

学習のエポック数（繰り返し数）は「likelihoodの数-1」である（最初の尤度は初期確率分布の尤度）。

＜用語＞
ColabFree・・・Google Colaboratoryの無料プランでの実行結果

＜浮動小数点＞
浮動小数点によって結果が大きく変わってしまう。
対策としてdecimal.Decimalを使う必要があるが、Numpyはこのデータ型を認識しない。
よって、一旦値を取り出した後は、float()でfloat（浮動小数点）にした後、Decimal(str())でDecimal型にして計算を行う。
そして、正確に計算された結果を再度Numpyに戻す（Decimal型としては認識されない）
しかし、numpyに代入するときfloatになって値が丸め込まれてしまう。これによって、誤差が生まれてしまうのでこの方針は却下。

どうやらlist型とDataFrameはDecimalに対応しているので、Numpy型をlist型に変えて計算を行う。
これによって、代入を除く全ての演算でDecimalを扱うことができた。

＜結果＞
Decimalを使っても、自分のPCでは安定しない。
10^n倍して整数(int)にして計算しても、恐らくsmoothmaxの処理で浮動小数点の問題が発生して安定しない。
roundでまとめてもやはり、浮動小数点の問題で安定しない。
よって、Google colabやMac proなどの正常に動くパソコンを用いて実験をする。
ただ、データ数が大きくなるとGoogleColabでも不安定になる可能性もある。

＜豆知識＞
delとかgc.collect()とかを消去するとめっちゃ速い。
